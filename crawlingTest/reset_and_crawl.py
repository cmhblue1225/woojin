#!/usr/bin/env python3
"""
í¬ë¡¤ë§ ìƒíƒœ ë¦¬ì…‹ í›„ ëŒ€ê·œëª¨ í¬ë¡¤ë§ ì‹¤í–‰
"""

import os
import shutil
import asyncio
import sys
from datetime import datetime

def reset_crawling_state():
    """í¬ë¡¤ë§ ìƒíƒœ ì™„ì „ ë¦¬ì…‹"""
    print("ğŸ”„ í¬ë¡¤ë§ ìƒíƒœ ë¦¬ì…‹ ì¤‘...")
    
    # ë°±ì—… ìƒì„±
    if os.path.exists('strategic_output'):
        backup_name = f"strategic_output_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        shutil.move('strategic_output', backup_name)
        print(f"ğŸ“ ê¸°ì¡´ ê²°ê³¼ ë°±ì—…: {backup_name}")
    
    # ìƒíƒœ íŒŒì¼ ë°±ì—… ë° ì‚­ì œ
    state_files = [
        'strategic_crawler_state.json',
        'strategic_crawler.log',
        'strategic_execution.log'
    ]
    
    for state_file in state_files:
        if os.path.exists(state_file):
            backup_name = f"{state_file}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            shutil.copy2(state_file, backup_name)
            os.remove(state_file)
            print(f"ğŸ“ ìƒíƒœ íŒŒì¼ ë¦¬ì…‹: {state_file}")
    
    # ìƒˆ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs('strategic_output', exist_ok=True)
    print("âœ… í¬ë¡¤ë§ ìƒíƒœ ë¦¬ì…‹ ì™„ë£Œ")

def main():
    print("=" * 60)
    print("ğŸ¯ ëŒ€ì§„ëŒ€í•™êµ ëŒ€ê·œëª¨ ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§")
    print("=" * 60)
    
    # ê¸°ì¡´ ë°ì´í„° í™•ì¸
    existing_files = 0
    if os.path.exists('enhanced_output'):
        existing_files = len([f for f in os.listdir('enhanced_output') if f.endswith('.txt')])
    
    print(f"ğŸ“Š í˜„ì¬ ìƒíƒœ:")
    print(f"   ê¸°ì¡´ ë°ì´í„°: {existing_files:,}ê°œ")
    print(f"   ëª©í‘œ ì‹ ê·œ: 5,000-10,000ê°œ")
    print(f"   ì „ì²´ ëª©í‘œ: 10,000-15,000ê°œ")
    
    print(f"\nğŸ”§ ìƒˆë¡œìš´ í¬ë¡¤ë§ ì„¤ì •:")
    print(f"   â€¢ ìš°ì„ ìˆœìœ„ URL: 50+ ê°œ í•™ê³¼/ê¸°ê´€")
    print(f"   â€¢ ìµœëŒ€ ê¹Šì´: 30ë‹¨ê³„ (ì»´ê³µê³¼)")
    print(f"   â€¢ ë™ì‹œ ì²˜ë¦¬: 8ê°œ Selenium ì¸ìŠ¤í„´ìŠ¤")
    print(f"   â€¢ í•„í„°ë§: ìµœì†Œí™”")
    print(f"   â€¢ ì˜ˆìƒ ì‹œê°„: 3-5ì‹œê°„")
    
    # í™•ì¸
    response = input(f"\nğŸš€ ëŒ€ê·œëª¨ í¬ë¡¤ë§ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
    if response.lower() not in ['y', 'yes']:
        print("âŒ í¬ë¡¤ë§ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return False
    
    # ìƒíƒœ ë¦¬ì…‹
    reset_crawling_state()
    
    try:
        print(f"\nğŸš€ ëŒ€ê·œëª¨ í¬ë¡¤ë§ ì‹œì‘...")
        print(f"   ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%H:%M:%S')}")
        print(f"   ì¤‘ë‹¨í•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.")
        
        # í¬ë¡¤ëŸ¬ import ë° ì‹¤í–‰
        from strategic_crawler import StrategicCrawler
        
        crawler = StrategicCrawler()
        
        # ëŒ€ê·œëª¨ í¬ë¡¤ë§ ì‹¤í–‰
        result = asyncio.run(crawler.run_strategic_crawling(max_pages=10000))
        
        print("\nâœ… ëŒ€ê·œëª¨ í¬ë¡¤ë§ ì™„ë£Œ!")
        
        # ê²°ê³¼ í™•ì¸
        if os.path.exists('strategic_output'):
            new_files = len([f for f in os.listdir('strategic_output') if f.endswith('.txt')])
            print(f"ğŸ“Š ìƒˆë¡œ ìˆ˜ì§‘ëœ í˜ì´ì§€: {new_files:,}ê°œ")
            
            if new_files >= 1000:
                print(f"ğŸ‰ ëª©í‘œ ë‹¬ì„±! ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
                print(f"ğŸ“ ê²°ê³¼ ìœ„ì¹˜: strategic_output/")
                print(f"ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: python3 merge_crawling_data.py")
                return True
            else:
                print(f"âš ï¸ ëª©í‘œì¹˜ë³´ë‹¤ ì ê²Œ ìˆ˜ì§‘ë¨. ì„¤ì • ì¬ì¡°ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                return False
        else:
            print("âŒ strategic_output ë””ë ‰í† ë¦¬ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
            
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("ğŸ”„ ìƒíƒœê°€ ì €ì¥ë˜ì—ˆìœ¼ë¯€ë¡œ ì¬ì‹œì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        return False
        
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"ğŸ“‹ ìì„¸í•œ ë¡œê·¸: strategic_crawler.log")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)