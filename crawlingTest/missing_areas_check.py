#!/usr/bin/env python3
"""
ëˆ„ë½ëœ ì˜ì—­ í™•ì¸ ë° ìš°ì„ ìˆœìœ„ URL ê²€ì¦
"""

import requests
import re
from urllib.parse import urlparse
import time

def check_url_status(url):
    """URL ì ‘ê·¼ ê°€ëŠ¥ì„± í™•ì¸"""
    try:
        response = requests.head(url, timeout=10, allow_redirects=True)
        return response.status_code == 200, response.status_code
    except Exception as e:
        return False, str(e)

def check_priority_urls():
    """ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ URL í™•ì¸"""
    
    # ì‚¬ìš©ìê°€ ëª…ì‹œí•œ ì¤‘ìš” URLë“¤
    priority_urls = [
        # ë©”ì¸ ì‚¬ì´íŠ¸ í•™ê³¼ë³„ í˜ì´ì§€
        "https://www.daejin.ac.kr/daejin/index.do",
        "https://www.daejin.ac.kr/daejin/877/subview.do",  # ìƒìƒêµì–‘ëŒ€í•™
        "https://www.daejin.ac.kr/daejin/869/subview.do",  # ëŒ€ìˆœì¢…í•™ëŒ€í•™  
        "https://www.daejin.ac.kr/daejin/870/subview.do",  # ì¸ë¬¸ì˜ˆìˆ ëŒ€í•™
        "https://www.daejin.ac.kr/daejin/871/subview.do",  # ê¸€ë¡œë²Œì‚°ì—…í†µìƒëŒ€í•™
        "https://www.daejin.ac.kr/daejin/872/subview.do",  # ê³µê³µì¸ì¬ëŒ€í•™
        "https://www.daejin.ac.kr/daejin/873/subview.do",  # ë³´ê±´ê³¼í•™ëŒ€í•™
        "https://www.daejin.ac.kr/daejin/874/subview.do",  # AIìœµí•©ëŒ€í•™
        "https://www.daejin.ac.kr/daejin/875/subview.do",  # ê³µê³¼ëŒ€í•™
        "https://www.daejin.ac.kr/daejin/5566/subview.do", # êµ­ì œí˜‘ë ¥ëŒ€í•™
        "https://www.daejin.ac.kr/daejin/876/subview.do",  # ë¯¸ë˜í‰ìƒêµìœ¡ìœµí•©ëŒ€í•™
        
        # ì»´í“¨í„°ê³µí•™ê³¼ ì¤‘ì 
        "https://ce.daejin.ac.kr/ce/index.do",
        "https://ce.daejin.ac.kr/ce/2518/subview.do",
        
        # ë„ì„œê´€ (ì–•ê²Œë§Œ)
        "https://library.daejin.ac.kr/main_main.mir",
        
        # ìƒ˜í”Œ ê²Œì‹œê¸€ URL
        "https://ce.daejin.ac.kr/ce/2518/subview.do?enc=Zm5jdDF8QEB8JTJGYmJzJTJGY2UlMkY2MDYlMkY0NTQxNTYlMkZhcnRjbFZpZXcuZG8lM0ZwYWdlJTNEMSUyNnNyY2hDb2x1bW4lM0QlMjZzcmNoV3JkJTNEJTI2YmJzQ2xTZXElM0QlMjZiYnNPcGVuV3JkU2VxJTNEJTI2cmdzQmduZGVTdHIlM0QlMjZyZ3NFbmRkZVN0ciUzRCUyNmlzVmlld01pbmUlM0RmYWxzZSUyNnBhc3N3b3JkJTNEJTI2"
    ]
    
    print("ğŸ” ìš°ì„ ìˆœìœ„ URL ì ‘ê·¼ì„± ê²€ì‚¬")
    print("=" * 60)
    
    accessible_urls = []
    inaccessible_urls = []
    
    for i, url in enumerate(priority_urls, 1):
        print(f"[{i:2d}/{len(priority_urls)}] ê²€ì‚¬ ì¤‘: {url}")
        
        is_accessible, status = check_url_status(url)
        
        if is_accessible:
            accessible_urls.append(url)
            print(f"    âœ… ì ‘ê·¼ ê°€ëŠ¥ (HTTP {status})")
        else:
            inaccessible_urls.append((url, status))
            print(f"    âŒ ì ‘ê·¼ ë¶ˆê°€ ({status})")
        
        time.sleep(0.5)  # ì†ë„ ì œí•œ
    
    print("\n" + "=" * 60)
    print(f"ğŸ“Š ê²°ê³¼ ìš”ì•½:")
    print(f"   âœ… ì ‘ê·¼ ê°€ëŠ¥: {len(accessible_urls)}ê°œ")
    print(f"   âŒ ì ‘ê·¼ ë¶ˆê°€: {len(inaccessible_urls)}ê°œ")
    
    if inaccessible_urls:
        print(f"\nâŒ ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•œ URL:")
        for url, status in inaccessible_urls:
            print(f"   - {url} ({status})")
    
    return accessible_urls, inaccessible_urls

def analyze_missing_patterns():
    """ê¸°ì¡´ ë°ì´í„°ì—ì„œ ëˆ„ë½ëœ íŒ¨í„´ ë¶„ì„"""
    
    print("\nğŸ” ëˆ„ë½ëœ íŒ¨í„´ ë¶„ì„")
    print("=" * 60)
    
    # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
    existing_urls = set()
    try:
        with open("enhanced_crawler_state.json", 'r', encoding='utf-8') as f:
            import json
            state = json.load(f)
            visited = state.get('visited', [])
            
            for url in visited:
                existing_urls.add(url)
            
            print(f"ğŸ“Š ê¸°ì¡´ URL ìˆ˜: {len(existing_urls):,}ê°œ")
            
    except Exception as e:
        print(f"âŒ ê¸°ì¡´ ìƒíƒœ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # íŒ¨í„´ë³„ ë¶„ì„
    patterns = {
        'www.daejin.ac.kr í•™ê³¼ í˜ì´ì§€': r'www\.daejin\.ac\.kr/daejin/\d+/subview\.do',
        'ce.daejin.ac.kr ê²Œì‹œê¸€': r'ce\.daejin\.ac\.kr/.*artclView\.do',
        'ce.daejin.ac.kr ì „ì²´': r'ce\.daejin\.ac\.kr',
        'ê²Œì‹œíŒ ê²Œì‹œê¸€ ì „ì²´': r'/bbs/.*/artclView\.do',
        'ë„ì„œê´€ í˜ì´ì§€': r'library\.daejin\.ac\.kr',
    }
    
    pattern_counts = {}
    for name, pattern in patterns.items():
        count = len([url for url in existing_urls if re.search(pattern, url)])
        pattern_counts[name] = count
        print(f"   {name}: {count:,}ê°œ")
    
    return pattern_counts

if __name__ == "__main__":
    # URL ì ‘ê·¼ì„± ê²€ì‚¬
    accessible, inaccessible = check_priority_urls()
    
    # ëˆ„ë½ íŒ¨í„´ ë¶„ì„  
    patterns = analyze_missing_patterns()
    
    print(f"\nğŸ¯ ì „ëµì  í¬ë¡¤ë§ ê¶Œì¥ì‚¬í•­:")
    print(f"   1. ì ‘ê·¼ ê°€ëŠ¥í•œ {len(accessible)}ê°œ ìš°ì„ ìˆœìœ„ URL ì§‘ì¤‘ í¬ë¡¤ë§")
    print(f"   2. ê° í•™ê³¼ ê²Œì‹œíŒ ê¹Šì´ ìš°ì„  íƒìƒ‰")
    print(f"   3. ë„ì„œê´€ì€ ë©”ì¸ í˜ì´ì§€ë§Œ ì–•ê²Œ ìˆ˜ì§‘")
    print(f"   4. ì˜ˆìƒ ì¶”ê°€ ìˆ˜ì§‘ëŸ‰: 2,000-3,000ê°œ í˜ì´ì§€")