#!/usr/bin/env node

/**
 * í¬ë¡¤ë§ ë°ì´í„° ë¶„ì„ ë° ì¤‘ë³µ ê²€ì‚¬ ìŠ¤í¬ë¦½íŠ¸
 * - 3ê°œ í¬ë¡¤ë§ í´ë”ì˜ ë°ì´í„° í’ˆì§ˆ ë¶„ì„
 * - URL ê¸°ë°˜ ì¤‘ë³µ ê²€ì‚¬
 * - ë„ë©”ì¸ë³„ ë¶„í¬ ë¶„ì„
 */

const fs = require('fs-extra');
const path = require('path');

class CrawlingDataAnalyzer {
    constructor() {
        this.basePath = path.join(__dirname, '../crawlingTest');
        this.folders = {
            enhanced_output: path.join(this.basePath, 'enhanced_output'),
            unlimited_crawling_output: path.join(this.basePath, 'unlimited_crawling_output'),
            enhanced_strategic_output: path.join(this.basePath, 'enhanced_strategic_output')
        };
        
        this.analysis = {
            folders: {},
            urlMap: new Map(),
            domainStats: {},
            duplicates: [],
            totalFiles: 0
        };
    }

    async analyzeFolders() {
        console.log('ğŸ” í¬ë¡¤ë§ ë°ì´í„° ë¶„ì„ ì‹œì‘...\n');
        
        for (const [folderName, folderPath] of Object.entries(this.folders)) {
            if (!await fs.pathExists(folderPath)) {
                console.log(`âš ï¸  í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: ${folderName}`);
                continue;
            }
            
            console.log(`ğŸ“ ${folderName} ë¶„ì„ ì¤‘...`);
            const folderAnalysis = await this.analyzeSingleFolder(folderName, folderPath);
            this.analysis.folders[folderName] = folderAnalysis;
            
            console.log(`   íŒŒì¼ ìˆ˜: ${folderAnalysis.fileCount.toLocaleString()}ê°œ`);
            console.log(`   í‰ê·  í¬ê¸°: ${Math.round(folderAnalysis.avgSize / 1024)}KB`);
            console.log(`   ë„ë©”ì¸ ìˆ˜: ${folderAnalysis.domains.length}ê°œ`);
            console.log(`   ì‹œê°„ ë²”ìœ„: ${folderAnalysis.timeRange.start} ~ ${folderAnalysis.timeRange.end}\n`);
        }
        
        await this.findDuplicates();
        await this.generateReport();
    }

    async analyzeSingleFolder(folderName, folderPath) {
        const files = await fs.readdir(folderPath);
        const txtFiles = files.filter(f => f.endsWith('.txt')).slice(0, 100); // ìƒ˜í”Œë§
        
        const analysis = {
            fileCount: files.filter(f => f.endsWith('.txt')).length,
            domains: new Set(),
            sizes: [],
            timeRange: { start: null, end: null },
            sampleFiles: []
        };
        
        this.analysis.totalFiles += analysis.fileCount;
        
        for (const file of txtFiles) {
            try {
                const filePath = path.join(folderPath, file);
                const content = await fs.readFile(filePath, 'utf8');
                const metadata = this.parseMetadata(content);
                
                if (metadata.url) {
                    // URL ì¤‘ë³µ ê²€ì‚¬ë¥¼ ìœ„í•œ ë§µ êµ¬ì¶•
                    if (this.analysis.urlMap.has(metadata.url)) {
                        this.analysis.urlMap.get(metadata.url).push({
                            folder: folderName,
                            file: file,
                            timestamp: metadata.timestamp,
                            length: metadata.length
                        });
                    } else {
                        this.analysis.urlMap.set(metadata.url, [{
                            folder: folderName,
                            file: file,
                            timestamp: metadata.timestamp,
                            length: metadata.length
                        }]);
                    }
                    
                    // ë„ë©”ì¸ ë¶„ì„
                    if (metadata.domain) {
                        analysis.domains.add(metadata.domain);
                        
                        if (!this.analysis.domainStats[metadata.domain]) {
                            this.analysis.domainStats[metadata.domain] = {
                                enhanced_output: 0,
                                unlimited_crawling_output: 0,
                                enhanced_strategic_output: 0
                            };
                        }
                        this.analysis.domainStats[metadata.domain][folderName]++;
                    }
                }
                
                // íŒŒì¼ í¬ê¸° ë° ì‹œê°„ ë¶„ì„
                const stat = await fs.stat(filePath);
                analysis.sizes.push(stat.size);
                
                if (metadata.timestamp) {
                    const timestamp = new Date(metadata.timestamp);
                    if (!analysis.timeRange.start || timestamp < new Date(analysis.timeRange.start)) {
                        analysis.timeRange.start = metadata.timestamp;
                    }
                    if (!analysis.timeRange.end || timestamp > new Date(analysis.timeRange.end)) {
                        analysis.timeRange.end = metadata.timestamp;
                    }
                }
                
                analysis.sampleFiles.push({
                    file,
                    url: metadata.url,
                    domain: metadata.domain,
                    length: metadata.length,
                    timestamp: metadata.timestamp
                });
                
            } catch (error) {
                console.log(`   âš ï¸  íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: ${file} - ${error.message}`);
            }
        }
        
        analysis.domains = Array.from(analysis.domains);
        analysis.avgSize = analysis.sizes.length > 0 ? 
            analysis.sizes.reduce((a, b) => a + b, 0) / analysis.sizes.length : 0;
        
        return analysis;
    }

    parseMetadata(content) {
        const lines = content.split('\n');
        const metadata = {};
        
        for (const line of lines.slice(0, 10)) { // ì²˜ìŒ 10ì¤„ë§Œ í™•ì¸
            if (line.startsWith('[URL]')) {
                metadata.url = line.replace('[URL]', '').trim();
            } else if (line.startsWith('[DOMAIN]')) {
                metadata.domain = line.replace('[DOMAIN]', '').trim();
            } else if (line.startsWith('[TIMESTAMP]')) {
                metadata.timestamp = line.replace('[TIMESTAMP]', '').trim();
            } else if (line.startsWith('[LENGTH]')) {
                metadata.length = parseInt(line.replace('[LENGTH]', '').trim());
            } else if (line.startsWith('[DEPTH]')) {
                metadata.depth = parseInt(line.replace('[DEPTH]', '').trim());
            }
        }
        
        return metadata;
    }

    async findDuplicates() {
        console.log('ğŸ” ì¤‘ë³µ URL ê²€ì‚¬ ì¤‘...');
        
        for (const [url, entries] of this.analysis.urlMap.entries()) {
            if (entries.length > 1) {
                // ë™ì¼ URLì— ëŒ€í•´ ìµœì‹ /ê³ í’ˆì§ˆ ë²„ì „ ì„ íƒ
                const sorted = entries.sort((a, b) => {
                    // 1. enhanced_strategic_output ìš°ì„ 
                    if (a.folder === 'enhanced_strategic_output' && b.folder !== 'enhanced_strategic_output') return -1;
                    if (b.folder === 'enhanced_strategic_output' && a.folder !== 'enhanced_strategic_output') return 1;
                    
                    // 2. íƒ€ì„ìŠ¤íƒ¬í”„ ìµœì‹ ìˆœ
                    if (a.timestamp && b.timestamp) {
                        return new Date(b.timestamp) - new Date(a.timestamp);
                    }
                    
                    // 3. ë‚´ìš© ê¸¸ì´ìˆœ
                    return (b.length || 0) - (a.length || 0);
                });
                
                this.analysis.duplicates.push({
                    url,
                    entries,
                    recommended: sorted[0], // ê¶Œì¥ ë²„ì „
                    duplicateCount: entries.length - 1
                });
            }
        }
        
        console.log(`   ë°œê²¬ëœ ì¤‘ë³µ URL: ${this.analysis.duplicates.length}ê°œ`);
    }

    async generateReport() {
        const reportPath = path.join(__dirname, '../crawling-analysis-report.json');
        const summaryPath = path.join(__dirname, '../crawling-analysis-summary.txt');
        
        // ìƒì„¸ ë³´ê³ ì„œ (JSON)
        await fs.writeJson(reportPath, this.analysis, { spaces: 2 });
        
        // ìš”ì•½ ë³´ê³ ì„œ (í…ìŠ¤íŠ¸)
        const summary = this.generateSummaryText();
        await fs.writeFile(summaryPath, summary, 'utf8');
        
        console.log(`\nğŸ“‹ ë¶„ì„ ì™„ë£Œ!`);
        console.log(`   ìƒì„¸ ë³´ê³ ì„œ: ${reportPath}`);
        console.log(`   ìš”ì•½ ë³´ê³ ì„œ: ${summaryPath}`);
        
        // ì½˜ì†”ì— ìš”ì•½ ì¶œë ¥
        console.log('\n' + '='.repeat(80));
        console.log(summary);
        console.log('='.repeat(80));
    }

    generateSummaryText() {
        const { folders, duplicates, domainStats, totalFiles } = this.analysis;
        
        let summary = `ğŸš€ ëŒ€ì§„ëŒ€ í¬ë¡¤ë§ ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œ\n`;
        summary += `ìƒì„± ì‹œê°„: ${new Date().toLocaleString('ko-KR')}\n\n`;
        
        summary += `ğŸ“Š ì „ì²´ í˜„í™©\n`;
        summary += `ì´ í¬ë¡¤ë§ íŒŒì¼: ${totalFiles.toLocaleString()}ê°œ\n`;
        summary += `ì¤‘ë³µ URL: ${duplicates.length}ê°œ\n`;
        summary += `ê³ ìœ  ë„ë©”ì¸: ${Object.keys(domainStats).length}ê°œ\n\n`;
        
        summary += `ğŸ“ í´ë”ë³„ ìƒì„¸ ì •ë³´\n`;
        for (const [folderName, data] of Object.entries(folders)) {
            summary += `\n${folderName}:\n`;
            summary += `  - íŒŒì¼ ìˆ˜: ${data.fileCount.toLocaleString()}ê°œ\n`;
            summary += `  - í‰ê·  í¬ê¸°: ${Math.round(data.avgSize / 1024)}KB\n`;
            summary += `  - ë„ë©”ì¸ ìˆ˜: ${data.domains.length}ê°œ\n`;
            summary += `  - ê¸°ê°„: ${data.timeRange.start || 'N/A'} ~ ${data.timeRange.end || 'N/A'}\n`;
        }
        
        summary += `\nğŸ† ìƒìœ„ ë„ë©”ì¸ (íŒŒì¼ ìˆ˜ ê¸°ì¤€)\n`;
        const sortedDomains = Object.entries(domainStats)
            .map(([domain, counts]) => ({
                domain,
                total: Object.values(counts).reduce((a, b) => a + b, 0),
                counts
            }))
            .sort((a, b) => b.total - a.total)
            .slice(0, 10);
        
        for (const { domain, total, counts } of sortedDomains) {
            summary += `${domain}: ${total}ê°œ `;
            summary += `(S:${counts.enhanced_strategic_output}, E:${counts.enhanced_output}, U:${counts.unlimited_crawling_output})\n`;
        }
        
        summary += `\nğŸ” ì¤‘ë³µ URL ìƒìœ„ 10ê°œ\n`;
        const topDuplicates = duplicates
            .sort((a, b) => b.duplicateCount - a.duplicateCount)
            .slice(0, 10);
        
        for (const dup of topDuplicates) {
            summary += `${dup.url} (${dup.duplicateCount + 1}íšŒ ì¤‘ë³µ)\n`;
            summary += `  ê¶Œì¥: ${dup.recommended.folder}/${dup.recommended.file}\n`;
        }
        
        summary += `\nğŸ’¡ í†µí•© ê¶Œì¥ì‚¬í•­\n`;
        summary += `1. enhanced_strategic_output (${folders.enhanced_strategic_output?.fileCount || 0}ê°œ) - ìµœìš°ì„  í†µí•©\n`;
        summary += `2. enhanced_output (${folders.enhanced_output?.fileCount || 0}ê°œ) - 2ìˆœìœ„ í†µí•©\n`;
        summary += `3. unlimited_crawling_output (${folders.unlimited_crawling_output?.fileCount || 0}ê°œ) - ë°°ì¹˜ ì²˜ë¦¬ í†µí•©\n`;
        summary += `\nì¤‘ë³µ ì œê±° í›„ ì˜ˆìƒ íŒŒì¼ ìˆ˜: ${totalFiles - duplicates.length}ê°œ\n`;
        
        return summary;
    }
}

// ì‹¤í–‰
if (require.main === module) {
    const analyzer = new CrawlingDataAnalyzer();
    analyzer.analyzeFolders().catch(console.error);
}

module.exports = CrawlingDataAnalyzer;